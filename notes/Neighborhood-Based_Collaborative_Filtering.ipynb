{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "3dc238ab-35d3-472d-8448-7b6a9869ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import timeit\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "e850276d-1fea-4427-9cfe-e60ecf06342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixUtil:\n",
    "    def __init__(self):\n",
    "        with open(\"../datasets/ecom_ratings/customers.json\") as f_:\n",
    "            self.users = json.load(f_)\n",
    "\n",
    "        with open(\"../datasets/ecom_ratings/products.json\") as f_:\n",
    "            self.products = json.load(f_)\n",
    "\n",
    "        with open(\"../datasets/ecom_ratings/ratings.json\") as f_:\n",
    "            self.ratings = json.load(f_)\n",
    "            \n",
    "        self.product_id_to_idx = {\n",
    "            product['Id']: idx\n",
    "            for idx, product in enumerate(self.products)\n",
    "        }\n",
    "        \n",
    "        self.idx_to_product_id = {\n",
    "            idx: id_ for id_, idx in self.product_id_to_idx.items()\n",
    "        }\n",
    "\n",
    "        self.user_id_to_idx = {\n",
    "            user['Id']: idx\n",
    "            for idx, user in enumerate(self.users)\n",
    "        }\n",
    "        \n",
    "        self.idx_to_user_id = {\n",
    "            idx: id_ for id_, idx in self.user_id_to_idx.items()\n",
    "        }\n",
    "        \n",
    "        self.matrix = self._generate_matrix()\n",
    "        \n",
    "    def _generate_matrix(self):\n",
    "        user_data = []\n",
    "        product_data = []\n",
    "        rating_data = []\n",
    "\n",
    "        for rating in ratings:\n",
    "            rating_data.append(rating['Rate'])    \n",
    "            user_data.append(self.user_id_to_idx[rating['CustomerID']])\n",
    "            product_data.append(self.product_id_to_idx[rating['ProductID']])\n",
    "\n",
    "        matrix = csr_matrix((rating_data, (user_data, product_data)), \n",
    "                            shape=(len(self.users), len(self.products))).toarray()\n",
    "        return matrix\n",
    "    \n",
    "    def get_user_vector(self, id_):\n",
    "        user_idx = self.user_id_to_idx.get(id_)\n",
    "        if user_idx == None:\n",
    "            raise ValueError(\"Provided id exist does not exist\")\n",
    "        return self.matrix[user_idx][:]\n",
    "    \n",
    "    def get_item_vector(self, id_):\n",
    "        item_idx = self.product_id_to_idx.get(id_)\n",
    "        if item_idx:\n",
    "            raise ValueError(\"Provided id exist does not exist\")\n",
    "        \n",
    "        return self.matrix[item_idx][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "0c2e3686-5fc5-4982-8b1d-1af3ffad2beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130754\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 127. GiB for an array with shape (130754, 130754) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_519/915599490.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatrixUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_519/3552662892.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         }\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_generate_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_519/3552662892.py\u001b[0m in \u001b[0;36m_generate_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         matrix = csr_matrix((rating_data, (user_data, product_data)), \n\u001b[0;32m---> 45\u001b[0;31m                             shape=(len(user_data), len(product_data))).toarray()\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/ecom_rec/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/ecom_rec/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 127. GiB for an array with shape (130754, 130754) and data type int64"
     ]
    }
   ],
   "source": [
    "mutil = MatrixUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca3639e8-2c7f-45c9-b41a-f336f17c3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = mutil.get_user_vector(103954)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30d871a8-2153-49e0-803b-649a30f9e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end goal is often either to:\n",
    "# 1. Predict a user's rating value of an item\n",
    "# 2. Predict the top-k items\n",
    "\n",
    "# Important to note that the first goal can be used to produce the second goal, albeit being less efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb50a3b-ac28-43cd-afdc-aa926a91f72c",
   "metadata": {},
   "source": [
    "# User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273a8f7-2335-478d-a87d-5cc836fa2367",
   "metadata": {},
   "source": [
    "The ratings provided by similar users to a target user are used to make recommendations for that user. The weighted average values of those similar users on an item k is used as the predicted rating for the target user on that item k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204443b3-dfcb-4104-b3ab-6eb2b4f992c0",
   "metadata": {},
   "source": [
    "### Issues\n",
    "\n",
    "1. Users may have different scales as one user may be biased towards liking most items and another user may be biased towards not liking at all.\n",
    "2. Users may have liked different items.\n",
    "\n",
    "To fix issue two, you take an intersection of the set of items liked by both users and use this to calculate similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c0bee-1e89-4183-b8f9-ce961cfc0137",
   "metadata": {},
   "source": [
    "### Finding similar users using Pearson correlation coefficient.\n",
    "\n",
    "The similarity metric uses items that have been rated by the target users and potential similar users as a vector.\n",
    "\n",
    "(1)\n",
    "$$ \n",
    "µ_{u} = \\frac{\\sum_{k∈I_u} r_{uk}}{|I_u|}\n",
    "$$\n",
    "\n",
    "\n",
    "(1.1)\n",
    "$$ \n",
    "Sim(u, v) = Pearson(u,v) = \\frac{\\sum_{k∈I_{u}∩I_{v}}(r_{uk} - µ_u) * (r_{vk} - µ_v)}{\\sqrt{\\sum_{k∈I_{u}∩I_{v}}(r_{uk} - µ_u)^2} * \\sqrt{\\sum_{k∈I_{u}∩I_{v}}(r_{vk} - µ_v)^2}}\n",
    "$$\n",
    "\n",
    "\n",
    "(1.2)\n",
    "$$ \n",
    "Sim(u, v) = Cosine(u,v) = \\frac{\\sum_{k∈I_{u}∩I_{v}}r_{uk} * r_{vk}}{\\sqrt{\\sum_{k∈I_{u}∩I_{v}}{r_{uk}}^2} * \\sqrt{\\sum_{k∈I_{u}∩I_{v}}{r_{vk}}^2}}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "$I_u$ is the set of items rated by user u.\n",
    "\n",
    "$r_{uk}$ is the rating a user u gives to an item k.\n",
    "\n",
    "$µ_{u}$ is the mean of the ratings for user u.\n",
    "\n",
    "The replacement of u with v in the variables above translates to the user v.\n",
    "\n",
    "### Cosine and Pearson Correlation\n",
    "\n",
    "Cosine similarity checks for the angular difference between two vectors in relation to the origin. This means that vectors [1, 1, 1, 1] (let's call it A) and [500, 500, 500, 500] (let's call it B) will have an angle of 0 despite having different magnitudes. Pearson correlation checks for a linear relationship between two datasets (in this case vectors A and vectors B are considered different distributions rather than a single). For example, if an increase in a variable in dataset a also leads to an increase in its corresponding item in dataset b, that can be considered to be a positive correlation. This concept of correlation can then be transferred to check the similarity between two vectors. Since Pearson correlation can be used to check for the relationship between two vectors, it is more discriminative compared to cosine similarity.\n",
    "\n",
    "References: https://blogs.sas.com/content/iml/2019/09/03/cosine-similarity.html, https://stats.stackexchange.com/questions/235673/is-there-any-relationship-among-cosine-similarity-pearson-correlation-and-z-sc, https://www.geeksforgeeks.org/python-pearson-correlation-test-between-two-variables/, https://leimao.github.io/blog/Cosine-Similarity-VS-Pearson-Correlation-Coefficient/\n",
    "\n",
    "\n",
    "### Question on calculating the mean of ratings...\n",
    "\n",
    "Since we are using the intersection of items rated between users. Should we not use then intersection as well when calculating the mean of a ratings for user u instead of using all of the items rated?\n",
    "\n",
    "#### Answer...\n",
    "\n",
    "1. It can be computationally expensive to calculate mean for each user u and v combination.\n",
    "2. It is hard to argue that the approach of using the intersection being better than using all the items or vice-versa.\n",
    "3. In cases where the intersection between two users is only 1 item, the similarity metric will fail because the part of eqn (1.1) that says $ (r_{uk} - µ_u) $ as that will yield zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "10cb5fbf-b755-4ff6-a051-741ecb776260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating(vector):\n",
    "    ratings = vector[vector != 0]\n",
    "    return round(ratings.sum() /len(ratings), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145cde57-7662-4c4b-b4e1-0fc3d88174ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "    \n",
    "# How Numpy einsum works:\n",
    "# https://ajcr.net/Basic-guide-to-einsum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "16bce980-2676-4fc9-afa1-c8942324a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_score(u_vec, v_vec):   \n",
    "    u_ratings_idx = np.where(u_vec != 0)\n",
    "    v_ratings_idx = np.where(v_vec != 0)\n",
    "    \n",
    "    intersecting_idx = np.intersect1d(u_ratings_idx, v_ratings_idx)\n",
    "    u_ratings = u_vec[intersecting_idx]\n",
    "    v_ratings = v_vec[intersecting_idx]\n",
    "        \n",
    "    num = np.multiply(u_ratings, v_ratings).sum()\n",
    "    \n",
    "    if num == 0:\n",
    "        return 0\n",
    "\n",
    "    u_mag = np.sqrt(np.dot(u_ratings, u_ratings))\n",
    "    v_mag = np.sqrt(np.dot(v_ratings, v_ratings))\n",
    "    \n",
    "    denum = u_mag * v_mag\n",
    "    \n",
    "    return round(num / denum, 6)\n",
    "\n",
    "def cos_sim_scores(u_vec, matrix):\n",
    "    matrix = deepcopy(matrix)\n",
    "    u_matrix = np.array([u_vec] * matrix.shape[0])\n",
    "    \n",
    "    for idx, val in enumerate(u_vec):\n",
    "        if val == 0:\n",
    "            matrix[:, idx] = 0      \n",
    "    u_matrix[matrix[:, :] == 0] = 0\n",
    "    \n",
    "    # Using einsum to calculate the diagonals of matrix multiplication without doing all of the multiplications\n",
    "    num = np.einsum('ij,ji->i', u_matrix, matrix.T)\n",
    "    u_mag = np.sqrt(np.einsum('ij,ji->i', u_matrix, u_matrix.T))\n",
    "    mag = np.sqrt(np.einsum('ij,ji->i', matrix, matrix.T))\n",
    "    denum = u_mag * mag\n",
    "    \n",
    "    with np.errstate(invalid='ignore'):\n",
    "        sim = np.around(num/denum, 6)\n",
    "        sim[np.isnan(sim)] = 0\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe70a7-d0ec-4608-b484-715cff801a65",
   "metadata": {},
   "source": [
    "### Calculating similarity score on multiple vectors\n",
    "\n",
    "One can easily find the similarity on multiple vectors by looping through each one and calling `cos_sim_score`, but I dug deeper and found a way to perform the calculations at the matrix level instead of the vector level. As seen in the cells below, going through each vector is slower than doing a matrix operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "16c969f8-53db-4b60-9d01-f785a732c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_scores_ineff(u_vec, matrix):\n",
    "    results = []\n",
    "    for v_vec in matrix:\n",
    "        results.append(cos_sim_score(u_vec, v_vec))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "4d2c5467-ce09-437a-8244-fb3bb59cb921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29 s ± 107 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for _ in range(100): cos_sim_scores_ineff(mutil.matrix[0], mutil.matrix[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "900198c0-0906-44a1-84eb-d4f7bb1166cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649 ms ± 37.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for _ in range(100): cos_sim_scores(mutil.matrix[0], mutil.matrix[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2d7aedc0-2cae-4d28-9408-f910e3f371aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gotcha\n",
    "# What to do with pearson correlation when the standard deviation is zero for one or both vectors?\n",
    "# https://stats.stackexchange.com/questions/18333/what-is-the-correlation-if-the-standard-deviation-of-one-variable-is-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4f2e94df-7d91-4409-813b-24d1fe2a6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pear_sim_score(u_vec, v_vec):\n",
    "    u_avg_rating = average_rating(u_vector)\n",
    "    v_avg_rating = average_rating(v_vector)\n",
    "    \n",
    "    u_ratings_idx = np.where(u_vector != 0)\n",
    "    v_ratings_idx = np.where(v_vector != 0)\n",
    "    \n",
    "    intersecting_idx = np.intersect1d(u_ratings_idx, v_ratings_idx)\n",
    "    u_ratings = u_vector[intersecting_idx]\n",
    "    v_ratings = v_vector[intersecting_idx]\n",
    "    \n",
    "    u_ratings = u_ratings - u_avg_rating\n",
    "    v_ratings = v_ratings - v_avg_rating\n",
    "    \n",
    "    # In cases where all ratings are zero as a result of subtracting the average, I assume no correlation.\n",
    "    if not any(v_ratings) or not any(u_ratings):\n",
    "        return 0\n",
    "        \n",
    "    num = np.multiply(u_ratings, v_ratings).sum()\n",
    "    u_mag = np.sqrt(np.dot(u_ratings, u_ratings))\n",
    "    v_mag = np.sqrt(np.dot(v_ratings, v_ratings))\n",
    "    denom = u_mag * v_mag\n",
    "    return round(num / denom, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fa852-4dab-4624-806a-0c2a75943667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pear_sim_scores_ineff(u_vec, matrix):\n",
    "    results = []\n",
    "    for v_vec in matrix:\n",
    "        results.append(pear_sim_score((u_vec, v_vec))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68e2ef-d059-4e4e-bffb-2afaeb086efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_vector = np.array([7, 6, 7, 4, 5, 4])\n",
    "# v_vector = np.array([0, 3, 3, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23254ef-a1a5-4c48-8261-b84496af18df",
   "metadata": {},
   "source": [
    "## Predicting Ratings\n",
    "\n",
    "To predict a target user's rating of an item, we rely on the ratings from other users and amplify or attenuate the impact of a rating from those users based on the similarity between them and the target user.\n",
    "\n",
    "(1.3)\n",
    "$$ \n",
    "\\hat{r}_{uj} = µ_u + \\frac{\\sum_{v∈P_u(j)}Sim(u, j) * r_{vj}}{\\sum_{v∈P_u(j)}|Sim(u, j)|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$P_u(j)$ is the set of users that are most similar to user **u**. The cardinality of this set could possibly be a max of 10.\n",
    "\n",
    "$Sim(u, j)$ is a similarity function that returns a score of how similar users u and j are.\n",
    "\n",
    "$µ_{u}$ is the mean of the ratings for user u.\n",
    "\n",
    "With equation 1.3 above, we are simply using the ratings of the most similar users to the target user **u**, then using the similarity between user u and those similar users to weigh how important their ratings should be. For example, a user with similarity 0.9 will have a rating with more impact than a user with similarity 0.2.\n",
    "\n",
    "#### Gotcha\n",
    "One has to calculate the set $P_u(j)$ for every item. Hence, the set is not a constant value for every user. This is because the most similar users to a target user at a global level, may not have an rating intersection on all items. Hence, calculating the set per item should be kept in mind.\n",
    "\n",
    "### Happy users and not so happy users.\n",
    "\n",
    "Some users tend to give high ratings to items regardless of how poor it is, while some tend to give low or average ratings regardless of how good an item is. Having users with tendency to rate low in the similarity set for an item when predicting ratings for a user that rates high can lead to predicting a low rating. To counter this problem, we center the ratings around the mean by subtracting the mean rating of each user from their rating of an item. \n",
    "\n",
    "Hence, fixing equation 1.3, we have:\n",
    "\n",
    "(1.4)\n",
    "$$ \n",
    "\\hat{r}_{uj} = µ_u + \\frac{\\sum_{v∈P_u(j)}Sim(u, j) * s_{vj}}{\\sum_{v∈P_u(j)}|Sim(u, j)|} = µ_u + \\frac{\\sum_{v∈P_u(j)}Sim(u, j) * (r_{vj} - µ_v)}{\\sum_{v∈P_u(j)}|Sim(u, j)|}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "0af0f451-831b-49b7-939e-6c2b639315ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_data(user_id, product_id, mutil, k=10):\n",
    "    user_idx = mutil.user_id_to_idx.get(user_id)\n",
    "    product_idx = mutil.product_id_to_idx.get(product_id)\n",
    "    above = mutil.matrix[:user_idx]\n",
    "    above = above[above[:,product_idx] != 0]\n",
    "    below = mutil.matrix[user_idx+1:]\n",
    "    below = below[below[:,product_idx] != 0]    \n",
    "    # candidate_matrix = np.concatenate((above, below))\n",
    "    candidate_matrix = below\n",
    "    return candidate_matrix\n",
    "    user_vector = mutil.matrix[user_idx]\n",
    "    # similarity_scores = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "ad530e70-a995-42af-a957-54009ad6a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, product_id, sim_func):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "d3b697eb-b533-4834-ba36-1db49c9f47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = get_similarity_data(103639, 1, mutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "71391686-8af5-4670-ab08-84497018ac08",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MatrixUtil' object has no attribute 'user_id_to_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_519/432390321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id_to_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m103639\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MatrixUtil' object has no attribute 'user_id_to_idx'"
     ]
    }
   ],
   "source": [
    "mutil.user_id_to_idx.get(103639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710128a-aa65-42a7-92ab-2c255082f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vector = matrix.get_user_vector(u_id)\n",
    "v_vector = matrix.get_user_vector(v_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c876c088-bf0a-4e54-b29e-416e6288aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 5, 5, 4, 0, 1, 0, 0, 1, 1, 5, 1, 0, 0, 0, 5, 0, 0, 0, 0,\n",
       "       5, 0, 1, 0, 1, 1, 0, 0, 4, 4, 0, 1, 1, 0, 0, 1, 0, 0, 4, 4, 0, 4,\n",
       "       4, 0, 4, 0, 4, 5, 4, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 5, 1, 0, 4,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 4, 1, 0, 0, 0, 5, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 5, 4, 1, 0, 0, 0, 0, 0, 5, 0, 1, 0, 1, 5,\n",
       "       5, 0, 0, 4, 0, 4, 1, 0, 0, 0, 0, 1, 4, 4, 0, 1, 0, 0, 0, 5, 1, 1,\n",
       "       1, 1, 0, 0, 0, 4, 4, 0, 1, 4, 1, 4, 1, 4, 1, 1, 1, 4, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 4, 0, 0, 0, 1, 0, 1, 4, 1, 0, 1, 0, 1, 0, 1, 4,\n",
       "       0, 5, 0, 0, 1, 4, 5, 0, 5, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       5, 5, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 5,\n",
       "       4, 0, 5, 0, 1, 0, 1, 4, 5, 4, 4, 0, 0, 0, 1, 4, 1, 0, 0, 0, 4, 0,\n",
       "       0, 0, 0, 5, 0, 0, 1, 0, 5, 5, 0, 4, 0, 4, 1, 0, 4, 4, 0, 0, 1, 1,\n",
       "       0, 1, 1, 4, 1, 1, 1, 4, 5, 1, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 5, 5,\n",
       "       0, 0, 1, 0, 0, 1, 4, 0, 4, 4, 0, 4, 5, 0, 1, 1, 0, 1, 0, 4, 1, 0,\n",
       "       5, 4, 0, 0, 0, 0, 0, 0, 1, 4, 0, 4, 0, 5, 1, 4, 0, 4, 1, 0, 0, 0,\n",
       "       4, 1, 1, 1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 4, 0, 1, 0, 4, 4, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 4, 0, 1, 0, 1, 4, 1, 0, 0, 5, 0, 0, 0, 0, 4, 1, 4, 0, 0,\n",
       "       4, 5, 1, 0, 1, 0, 0, 0, 0, 1, 5, 1, 0, 0, 1, 1, 1, 4, 0, 1, 0, 1,\n",
       "       0, 0, 4, 1, 0, 1, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 4, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 4, 1, 1, 0, 4,\n",
       "       0, 0, 4, 0, 0, 0, 1, 0, 0, 5, 0, 4, 0, 0, 1, 1, 0, 1, 0, 0, 4, 1,\n",
       "       0, 4, 1, 0, 4, 1, 1, 0, 0, 0, 1, 0, 1, 5, 0, 1, 0, 0, 4, 0, 0, 1,\n",
       "       0, 0, 4, 0, 0, 1, 0, 5, 0, 1, 0, 4, 1, 1, 0, 5, 5, 5, 0, 1, 0, 5,\n",
       "       0, 4, 0, 0, 4, 0, 0, 0, 1, 4, 0, 1, 5, 1, 0, 4, 5, 5, 1, 0, 5, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 4, 1, 0, 0, 4, 0,\n",
       "       1, 5, 1, 1, 0, 1, 5, 4, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 4, 1, 1, 1, 5, 0, 4, 0, 1, 0, 0, 1, 0, 0, 4,\n",
       "       4, 1, 0, 1, 1, 0, 1, 1, 1, 1, 5, 0, 0, 0, 4, 5, 1, 1, 4, 1, 5, 0,\n",
       "       0, 4, 4, 5, 4, 1, 0, 0, 4, 4, 0, 0, 1, 1, 4, 0, 0, 0, 0, 1, 1, 5,\n",
       "       5, 0, 0, 5, 5, 1, 0, 1, 0, 1, 4, 0, 1, 1, 0, 1, 0, 5, 1, 5, 5, 1,\n",
       "       0, 0, 4, 0, 4, 0, 5, 0, 0])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutil.get_user_vector(103639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e5d77671-dd5c-4b27-80d8-7daac0f22cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 103954\n",
    "# 103603\n",
    "# 103654\n",
    "# 103806\n",
    "\n",
    "# Test vectors\n",
    "# u_vector = np.array([7, 6, 7, 4, 5, 4])\n",
    "# v_vector = np.array([0, 3, 3, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c88ca-f2b0-45e2-81d4-3be0083350e1",
   "metadata": {},
   "source": [
    "# Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8171f-f9ba-48f2-8495-35d6582c7c08",
   "metadata": {},
   "source": [
    "The items similar to a target item are retrieved. Then the user's ratings on those similar items extracted with their weighted average calculated. This calculated average becomes the predicted rating for that item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583079fa-5856-49ac-988a-7c58a7cf3103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
